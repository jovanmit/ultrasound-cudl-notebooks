{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DeepBF-alike Architecture for Compressive Beamforming </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import all of the libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:01.163310Z",
     "start_time": "2020-06-03T20:16:48.246499Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hero/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import scipy.io as spio\n",
    "import gc\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import imageio\n",
    "import cv2\n",
    "import tensorflow\n",
    "import keras\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from scipy.signal import hilbert\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import *\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is used to define couple of loss functions used for some of the advanced applications. This is entirely up to the user whether to run, and is provided only so that there is no need to try an implement these functions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:01.478464Z",
     "start_time": "2020-06-03T20:17:01.164946Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "alpha=K.constant(0.9)\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred-y_true))\n",
    "\n",
    "def mixed_error(y_true, y_pred):\n",
    "    return (alpha*K.abs(K.abs(K.mean(K.square(y_pred - y_true))))+(1-alpha)*K.mean(K.abs(y_pred - y_true)))\n",
    "\n",
    "def log10(x):\n",
    "    numerator = K.log(x)\n",
    "    denominator = K.log(K.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = K.constant(1.0)\n",
    "    return (10.0 * log10((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1))))\n",
    "\n",
    "def one_over_psnr(y_true, y_pred):\n",
    "    return 1/PSNR(y_true, y_pred)\n",
    "\n",
    "def loss_psnr(y_true, y_pred):\n",
    "    mse = K.mean(K.square(y_pred-y_true), axis=-1)\n",
    "    psnr = PSNR(y_true, y_pred)#K.image.psnr(y_true, y_pred, max_val = 1.0)\n",
    "    return 1 - (10*log10(1/mse))\n",
    "\n",
    "def loss_smsle(y_true, y_pred):\n",
    "#     ytp = K.gather(y_true,K.greater_equal(y_true,0))\n",
    "#     ytn = K.gather(y_true,K.less(y_true,0))\n",
    "#     ypp = K.gather(y_pred,K.greater_equal(y_pred,0))\n",
    "#     ypn = K.gather(y_pred,K.less(y_pred,0))\n",
    "    return 1/2*MSE(log10(K.relu(y_pred)+1),log10(K.relu(y_true)+1))+1/2*MSE(log10(K.relu(-y_pred)+1),log10(K.relu(-y_true)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:01.492019Z",
     "start_time": "2020-06-03T20:17:01.481493Z"
    }
   },
   "outputs": [],
   "source": [
    "class Antirectifier(Layer):\n",
    "    def __init__(self, initializer=\"he_normal\", **kwargs):\n",
    "        super(Antirectifier, self).__init__(**kwargs)\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        output_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(output_dim * 2, output_dim),\n",
    "            initializer=self.initializer,\n",
    "            name=\"kernel\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs -= tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        pos = tf.nn.relu(inputs)\n",
    "        neg = tf.nn.relu(-inputs)\n",
    "        concatenated = tf.concat([pos, neg], axis=-1)\n",
    "        mixed = tf.matmul(concatenated, self.kernel)\n",
    "        return mixed\n",
    "\n",
    "    def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "        base_config = super(Antirectifier, self).get_config()\n",
    "        config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. There are several lines of code that were being used as an experimentation for determining the appropriate normalization for this type of data. The next cell performs normalization in terms of dividing by the largest value.\n",
    "\n",
    "The data split is up to the user, and for the sake of simplicity, the validation set is the same as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:31.415680Z",
     "start_time": "2020-06-03T20:17:01.940870Z"
    }
   },
   "outputs": [],
   "source": [
    "a=0\n",
    "b=1\n",
    "size_train=180\n",
    "size_test=20\n",
    "rf_place = 'RF_realdata_4smpl_carotid/Comp8/RcvData'\n",
    "img_place = 'IQData_realdata_4smpl_carotid/IQData'\n",
    "length=1100\n",
    "start_smpl=100\n",
    "trainRF=np.empty([(length-start_smpl)*size_train,16,128,3], dtype='int32')\n",
    "trainIMG=np.empty([(length-start_smpl)*size_train,2,128,1])\n",
    "testRF=np.empty([(length-start_smpl)*size_test,16,128,3], dtype='int32')\n",
    "testIMG=np.empty([(length-start_smpl)*size_test,2,128,1])\n",
    "\n",
    "for size in range(size_train):\n",
    "    #RcvData\n",
    "    RcvData = spio.loadmat(rf_place+str(size+1)+'.mat', squeeze_me=True)\n",
    "    RcvData = RcvData['compressed']#/np.max(RcvData['compressed'])    # MAYBE THIS HELPS? SEEMS LIKE IT DOESN'T\n",
    "    trainRF_temp=np.empty([length-start_smpl,16,128,3])\n",
    "    matrix_rf=np.empty([length-start_smpl,128,16])\n",
    "    j=0\n",
    "    for cnt in range(128):\n",
    "        matrix_rf[:,cnt,:]=RcvData[start_smpl:length,:,cnt]\n",
    "#     matrix_rf_trans=np.dstack((np.zeros([16,128,1]),matrix_rf.T,np.zeros([16,128,1])))\n",
    "    matrix_rf_trans=matrix_rf.T\n",
    "    for i in range(length-start_smpl-2):\n",
    "        trainRF_temp[i]=matrix_rf_trans[:,:,i:i+3]\n",
    "    trainRF[size*(length-start_smpl):(size+1)*(length-start_smpl)]=trainRF_temp\n",
    "    \n",
    "#trainRF is [num, channel_no, rayline, depth]\n",
    "    \n",
    "    #IQ data\n",
    "    trainIMG_temp = spio.loadmat(img_place+str(size+1)+'.mat', squeeze_me=True)\n",
    "    trainIMG_temp = trainIMG_temp['interData'][start_smpl:length-2,:]\n",
    "    trainIMG_temp1 = np.empty([length-start_smpl-2,128,2])\n",
    "    trainIMG_temp1[:,:,0]=trainIMG_temp.real\n",
    "    trainIMG_temp1[:,:,1]=trainIMG_temp.imag\n",
    "#     trainIMG_temp1= trainIMG_temp1[start_smpl:length,:,:]\n",
    "#     trainIMG_temp1 = trainIMG_temp1 / np.absolute(trainIMG_temp1).max()\n",
    "#     trainIMG_temp1 = (trainIMG_temp1-trainIMG_temp1.min())/(trainIMG_temp1.max()-trainIMG_temp1.min())\n",
    "#     trainIMG_temp1 = a+((trainIMG_temp1-np.absolute(trainIMG_temp).min())*(b-a))/(np.absolute(trainIMG_temp).max()-np.absolute(trainIMG_temp).min())      # THIS MAKES A MESS! WHY? IT works w abs\n",
    "#     trainIMG_temp1 = (trainIMG_temp1 >= 0.0032)*trainIMG_temp1 + 0.0032*(trainIMG_temp1<0.0032)\n",
    "    trainIMG[size*(length-start_smpl-2):(size+1)*(length-start_smpl-2),0,:,0]=trainIMG_temp1[:,:,0]\n",
    "    trainIMG[size*(length-start_smpl-2):(size+1)*(length-start_smpl-2),1,:,0]=trainIMG_temp1[:,:,1]\n",
    "#     comp = (comp>=0.0032)*comp+0.0032*(comp<0.0032)\n",
    "    \n",
    "#TEST\n",
    "for size in range(size_test):\n",
    "    #RcvData\n",
    "    RcvData = spio.loadmat(rf_place+str(size_train+size+1)+'.mat', squeeze_me=True)\n",
    "    RcvData = RcvData['compressed']#/np.max(RcvData['compressed'])    # MAYBE THIS HELPS?\n",
    "    trainRF_temp=np.empty([length-start_smpl,16,128,3])\n",
    "    matrix_rf=np.empty([length-start_smpl,128,16])\n",
    "    j=0\n",
    "    for cnt in range(128):\n",
    "        matrix_rf[:,cnt,:]=RcvData[start_smpl:length,:,cnt]\n",
    "#     matrix_rf_trans=np.dstack((np.zeros([16,128,1]),matrix_rf.T,np.zeros([16,128,1])))\n",
    "        matrix_rf_trans=matrix_rf.T\n",
    "    for i in range(length-start_smpl-2):\n",
    "        trainRF_temp[i]=matrix_rf_trans[:,:,i:i+3]\n",
    "    testRF[size*(length-start_smpl):(size+1)*(length-start_smpl)]=trainRF_temp\n",
    "    \n",
    "    #IQ data\n",
    "    trainIMG_temp = spio.loadmat(img_place+str(size_train+size+1)+'.mat', squeeze_me=True)\n",
    "    trainIMG_temp = trainIMG_temp['interData'][start_smpl:length-2,:]\n",
    "    trainIMG_temp1 = np.empty([length-start_smpl-2,128,2])\n",
    "    trainIMG_temp1[:,:,0]=trainIMG_temp.real\n",
    "    trainIMG_temp1[:,:,1]=trainIMG_temp.imag\n",
    "#     trainIMG_temp1= trainIMG_temp1[start_smpl:length,:,:]\n",
    "#     trainIMG_temp1 = trainIMG_temp1 / np.absolute(trainIMG_temp1).max()\n",
    "#     trainIMG_temp1 = (trainIMG_temp1-trainIMG_temp1.min())/(trainIMG_temp1.max()-trainIMG_temp1.min())\n",
    "#     trainIMG_temp1 = a+((trainIMG_temp1-np.absolute(trainIMG_temp).min())*(b-a))/(np.absolute(trainIMG_temp).max()-np.absolute(trainIMG_temp).min())      # THIS MAKES A MESS! WHY? IT works w abs\n",
    "#     trainIMG_temp1 = (trainIMG_temp1 >= 0.0032)*trainIMG_temp1 + 0.0032*(trainIMG_temp1<0.0032)\n",
    "    testIMG[size*(length-start_smpl-2):(size+1)*(length-start_smpl-2),0,:,0]=trainIMG_temp1[:,:,0]\n",
    "    testIMG[size*(length-start_smpl-2):(size+1)*(length-start_smpl-2),1,:,0]=trainIMG_temp1[:,:,1]\n",
    "    \n",
    "validRF=testRF\n",
    "validIMG=testIMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:31.755201Z",
     "start_time": "2020-06-03T20:17:31.416902Z"
    }
   },
   "outputs": [],
   "source": [
    "img_max = np.absolute(trainIMG).max()\n",
    "trainIMG=trainIMG/img_max\n",
    "testIMG = testIMG/img_max\n",
    "validIMG = validIMG/img_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates the neural network.\n",
    "\n",
    "There are a lot of parameters in the first part of the cell, and they are explained in more details in the report itself. \n",
    "\n",
    "All of the layers are created using the \"exec\" function, which executes a string. This is used in order to iterate through layers using a for loop, and to apply all of the necessary modifiers and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:41.722816Z",
     "start_time": "2020-06-03T20:17:31.762737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hero/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1 (Conv2D)               (None, 16, 128, 3)   768         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 128, 3)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_1 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 128, 3)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_2 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 128, 3)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_3 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 128, 3)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_4 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 128, 3)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_5 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 128, 3)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_6 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 128, 3)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_7 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 128, 3)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_8 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 128, 3)   768         antirectifier_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 128, 3)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_9 (Antirectifier) (None, 16, 128, 3)   18          batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 128, 3)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_10 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 128, 3)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_11 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 128, 3)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_12 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 128, 3)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_13 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 128, 3)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_14 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 128, 3)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_15 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 128, 3)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_16 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 128, 3)   0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 128, 3)   64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_17 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 128, 3)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_18 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 128, 3)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_19 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 128, 3)   64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_20 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 128, 3)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 128, 3)   64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_21 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 128, 3)   64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_22 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 128, 3)   64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_23 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 128, 3)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_24 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 128, 3)   0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 128, 3)   64          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_25 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 128, 3)   64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_26 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 128, 3)   64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_27 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 128, 3)   64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "antirectifier_28 (Antirectifier (None, 16, 128, 3)   18          batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 128, 3)   768         antirectifier_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 128, 3)   768         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 128, 1)   768         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 128, 1)    0           conv2d_31[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,104\n",
      "Trainable params: 25,208\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=trainRF.shape\n",
    "k=4\n",
    "num_filters=16\n",
    "num_filters_last=2\n",
    "kernel_size=(1,3)\n",
    "k_reg_l1=0#1e-4    # PLAY W THIS\n",
    "k_reg_l2=0#1e-4\n",
    "k_reg_l1_last=0#1e-4\n",
    "k_reg_l2_last=0#1e-5\n",
    "b_reg_l1=0\n",
    "b_reg_l2=0#3e-1\n",
    "act_reg_l1=0\n",
    "act_reg_l2=0#1e-6\n",
    "act_reg_l1_last=0\n",
    "act_reg_l2_last=0#1e-6\n",
    "layer_act='linear'\n",
    "postnorm_act='relu'\n",
    "bnorm=True\n",
    "use_bias=False\n",
    "inputs = Input(shape = input_shape[1:])\n",
    "\n",
    "size=4*(k*2+1)\n",
    "\n",
    "for i in range(1,size+1):\n",
    "    if i==1:\n",
    "        exec('conv'+str(i)+'=Conv2D('+str(num_filters)+',kernel_size='+str(kernel_size)+',activation=\"'+str(layer_act)+'\",padding=\"same\",kernel_initializer=\"glorot_normal\",use_bias='+str(use_bias)+',data_format=\"channels_first\", activity_regularizer=l1_l2(l1='+str(act_reg_l1)+',l2='+str(act_reg_l2)+'), kernel_regularizer=l1_l2(l1='+str(k_reg_l1)+',l2='+str(k_reg_l2)+'), bias_regularizer=l1_l2(l1='+str(b_reg_l1)+',l2='+str(b_reg_l2)+'))(inputs)')\n",
    "    else:\n",
    "        exec('conv'+str(i)+'=Conv2D('+str(num_filters)+',kernel_size='+str(kernel_size)+',activation=\"'+str(layer_act)+'\",padding=\"same\",kernel_initializer=\"glorot_normal\",use_bias='+str(use_bias)+',data_format=\"channels_first\", activity_regularizer=l1_l2(l1='+str(act_reg_l1)+',l2='+str(act_reg_l2)+'), kernel_regularizer=l1_l2(l1='+str(k_reg_l1)+',l2='+str(k_reg_l2)+'), bias_regularizer=l1_l2(l1='+str(b_reg_l1)+',l2='+str(b_reg_l2)+'))(act'+str((i-1))+')')\n",
    "    if (i-1)%4==0 and (i-1)/4>k:\n",
    "        concat_loc = ((size-i+1)//4-1)*4 + 1\n",
    "#         exec('add'+str(i)+'=concatenate([conv'+str(concat_loc)+', conv'+str(i)+'], axis=1)')\n",
    "        exec('add'+str(i)+'=add([conv'+str(concat_loc)+', conv'+str(i)+'])')\n",
    "        if bnorm:\n",
    "            exec('norm'+str(i)+'=BatchNormalization(axis=1)(add'+str(i)+')')\n",
    "    else:\n",
    "        if bnorm:\n",
    "            exec('norm'+str(i)+'=BatchNormalization(axis=1)(conv'+str(i)+')')\n",
    "    if bnorm:\n",
    "        exec('act'+str(i)+'=Antirectifier()(norm'+str(i)+')')\n",
    "    else:\n",
    "        if (i-1)%4==0 and (i-1)/4>k:\n",
    "            exec('act'+str(i)+'=Antirectifier()(add'+str(i)+')')\n",
    "        else:\n",
    "            exec('act'+str(i)+'=Antirectifier()(conv'+str(i)+')')\n",
    "\n",
    "exec('final=Conv2D('+str(num_filters)+',kernel_size=(1,3),kernel_initializer=\"glorot_normal\",use_bias='+str(use_bias)+',padding=\"same\", data_format=\"channels_first\", activation=\"linear\", activity_regularizer=l1_l2(l1='+str(act_reg_l1_last)+',l2='+str(act_reg_l2_last)+'), kernel_regularizer=l1_l2(l1='+str(k_reg_l1_last)+',l2='+str(k_reg_l2_last)+'), bias_regularizer=l1_l2(l1='+str(b_reg_l1)+',l2='+str(b_reg_l2)+'))(act'+str(size)+')')\n",
    "\n",
    "out = AveragePooling2D(pool_size=(num_filters//2,1), data_format='channels_last', padding='valid')(final)\n",
    "\n",
    "model=Model(input = inputs, output = out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of one-cycle SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:17:42.597963Z",
     "start_time": "2020-06-03T20:17:41.724855Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Implement One Cycle Policy Algorithm in the Keras Callback Class\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras import backend as K\n",
    "from keras.callbacks import *\n",
    "\n",
    "class CyclicLR(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
    " \n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.base_m = base_m\n",
    "        self.max_m = max_m\n",
    "        self.cyclical_momentum = cyclical_momentum\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        self.clr_iterations = 0.\n",
    "        self.cm_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
    "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
    "    \n",
    "    def cm(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            \n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
    "            return self.max_m\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "            \n",
    "        if self.cyclical_momentum == True:\n",
    "            if self.clr_iterations == 0:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            else:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            \n",
    "            \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, training the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:49.621894Z",
     "start_time": "2020-06-03T20:17:42.599834Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hero/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "180000/180000 [==============================] - 201s 1ms/step - loss: 0.0012 - val_loss: 9.5586e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00096, saving model to best_model.h5\n",
      "Epoch 2/3\n",
      "180000/180000 [==============================] - 195s 1ms/step - loss: 0.0011 - val_loss: 8.9618e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00096 to 0.00090, saving model to best_model.h5\n",
      "Epoch 3/3\n",
      "180000/180000 [==============================] - 196s 1ms/step - loss: 0.0011 - val_loss: 8.8331e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00090 to 0.00088, saving model to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# CLR parameters\n",
    "\n",
    "batch_size = 336\n",
    "ep = 3\n",
    "max_lr = 1e-3\n",
    "base_lr = 1e-7\n",
    "max_m = 0.5\n",
    "base_m = 0.2\n",
    "\n",
    "cyclical_momentum = True\n",
    "augment = True\n",
    "cycles = 2.1\n",
    "\n",
    "iterations = round(trainRF.shape[0]/batch_size*ep)\n",
    "iterations = list(range(0,iterations+1))\n",
    "step_size = len(iterations)/(cycles)\n",
    "\n",
    "\n",
    "model.compile(loss=loss_smsle, optimizer=SGD(1e-4))\n",
    "\n",
    "clr =  CyclicLR(base_lr=base_lr,\n",
    "                max_lr=max_lr,\n",
    "                step_size=step_size,\n",
    "                max_m=max_m,\n",
    "                base_m=base_m,\n",
    "                cyclical_momentum=cyclical_momentum)\n",
    "    \n",
    "callbacks = [clr,\n",
    "            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',mode='min',verbose=1,save_best_only=True)]\n",
    "\n",
    "history = model.fit(trainRF, \n",
    "                    trainIMG, \n",
    "                    epochs=ep, \n",
    "                    verbose=1, \n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(testRF, testIMG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a typical optimizers are to be used (not a one-cycle SGD as implemented above) then the following cells need to be uncommented and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:49.625762Z",
     "start_time": "2020-06-03T20:27:49.623552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # model = Model(input = inputs, output = out)\n",
    "# ep = 5\n",
    "# learning_rate = 1e-3\n",
    "# decay_rate = learning_rate/(ep)\n",
    "# opt = keras.optimizers.Adam(lr=learning_rate, decay = decay_rate)\n",
    "\n",
    "# model.compile(optimizer = opt, loss = loss_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:49.671806Z",
     "start_time": "2020-06-03T20:27:49.627219Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # callbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',mode='min',verbose=1,save_best_only=True)]\n",
    "\n",
    "# history = model.fit(trainRF,\n",
    "#                     trainIMG,\n",
    "#                     epochs=ep,\n",
    "#                     verbose=1,\n",
    "# #                     callbacks=callbacks,\n",
    "#                     batch_size=336,\n",
    "#                     validation_data=(testRF, testIMG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, a trained model can be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:49.732683Z",
     "start_time": "2020-06-03T20:27:49.674125Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('sgd_one_cycle_ksize_3_3_200ep_carotid_diffnormalization')\n",
    "# model=load_model('best_model.h5', custom_objects={ 'loss_psnr': loss_psnr })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the verificaiton part. Apart from the loss that we can observe throughout the training, a resulting image needs to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:57.475007Z",
     "start_time": "2020-06-03T20:27:49.735201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 8s 383us/step\n"
     ]
    }
   ],
   "source": [
    "pp=model.predict(validRF, verbose=1, batch_size=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:27:57.832006Z",
     "start_time": "2020-06-03T20:27:57.476040Z"
    }
   },
   "outputs": [],
   "source": [
    "pp1=pp[:,:,:,0]\n",
    "pp2=pp1[:,0,:]+1j*pp1[:,1,:]\n",
    "pp3=np.absolute(pp2)\n",
    "testIMG2=testIMG[:,:,:,0]\n",
    "testIMG3=testIMG2[:,0,:]+1j*testIMG2[:,1,:]\n",
    "testIMG4=np.absolute(testIMG3)\n",
    "validIMG2=validIMG[:,:,:,0]\n",
    "validIMG3=validIMG2[:,0,:]+1j*validIMG2[:,1,:]\n",
    "validIMG4=np.absolute(validIMG3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:28:00.784976Z",
     "start_time": "2020-06-03T20:27:57.833247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hero/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['maximum', 'copy', 'average', 'dot', 'size', 'ones', 'multiply', 'concatenate', 'zeros', 'log10', 'get', 'add', 'identity', 'normal', 'minimum', 'subtract', 'uniform']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Plotting\n",
    "pic_no=10\n",
    "start=0\n",
    "end=1000\n",
    "offset=100#12*10\n",
    "dyn_range=-70\n",
    "dyn_range_comp=-70\n",
    "dr_db=10**(dyn_range/20)\n",
    "dr_db_comp=10**(dyn_range_comp/20)\n",
    "%pylab\n",
    "comp = pp3[pic_no*length+start+offset:(pic_no)*length+end+offset]\n",
    "comp = comp/np.max(comp)\n",
    "# comp=1-comp\n",
    "comp = (comp>=dr_db_comp)*comp+dr_db_comp*(comp<dr_db_comp)\n",
    "\n",
    "orig = validIMG4[pic_no*length+start:(pic_no)*length+end]\n",
    "orig = orig/np.max(orig)\n",
    "orig = (orig>=dr_db)*orig+dr_db*(orig<dr_db)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()#figsize=(200,10))\n",
    "# axes1=fig1.add_axes([0,0,end-start, 128])\n",
    "plt.imshow(orig, extent=[0,128,end,start], aspect=0.1)#, cmap=plt.cm.get_cmap('gray'))\n",
    "# plt.imshow(orig)#, cmap=plt.cm.get_cmap('gray'))\n",
    "plt.figure()#figsize=(200,10))\n",
    "plt.imshow(comp, extent=[0,128,end,start], aspect=0.1)#, cmap=plt.cm.get_cmap('gray'))#, cmap=plt.cm.get_cmap('gray'))\n",
    "# plt.show()\n",
    "# plt.figure()\n",
    "# plt.imshow(orig-comp,extent=[0,128,end,start], aspect=0.1)\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "485.85px",
    "left": "633.533px",
    "right": "20px",
    "top": "95px",
    "width": "623.467px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
